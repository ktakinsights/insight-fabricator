{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44be77dd",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7873f",
   "metadata": {},
   "source": [
    "This is a supplement to the main report available on the Medicare claims data.  As with the base analysis, a better understanding of the data can help inform better decision-making.  We already looked at how spending is different across age groups, gender, and other factors.  The exploratory data analysis included some visualizations and basic statistical tests.  This extension will include three stages of more advanced analytical techniques.  We will focus on specific medical procedures, try to predict future costs and find new insights by comparing different parts of the data. This new project will give us a better understanding of Medicare spending."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30205023",
   "metadata": {},
   "source": [
    "# Predictive Modeling\n",
    "Predictive modeling creates a learning model to predict healthcare expenditures.  It uses demographic factors, DRG codes, procedure codes, and other relevant variables to guess what a future claim might cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e9cd40",
   "metadata": {},
   "source": [
    "## Choosing relevant features\n",
    "In our dataset, we have six variables. Since our goal is to predict the cost of a claim, we're left with five potential features to include in our model.  Age, gender, type of procedure, diagnosis, and length of hospital stay all seem important to include.\n",
    "\n",
    "We conducted Chi-square tests for goodness of fit on gender and independence tests for pairs of variables. The results of these tests indicate our selected features are likely independent and suitable for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487913f9",
   "metadata": {},
   "source": [
    "## Our models\n",
    "We have selected Stochastic Gradient Descent (SGD) Regression, SGD Classification, and Random Forest as our machine learning models. These models represent a diverse range of techniques and cater to different types of problems.\n",
    "\n",
    "SGD Regression: This model is chosen for predicting continuous target variables, such as the average claim amount within each quintile bin. SGD Regression is a more efficient variant of linear regression models designed for large-scale datasets. It is based on linear relationships between features and the target variable.\n",
    "\n",
    "SGD Classification: This model is used for classification issues, such as predicting the claim amount quintile bin for each observation.  It is similar to the previous model, though for predicting a category instead of predicting a quantity.\n",
    "\n",
    "Random Forest Regression: This model is used when relationships between variables are complex. It leverages multiple decision trees to make predictions, efficiently handling high dimensional spaces and large data sets. Moreover, it provides insights into influential variables and is robust against overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da834fac",
   "metadata": {},
   "source": [
    "## Model training and evaluation\n",
    "To train and evaluate our models, we will use the following process:\n",
    "\n",
    "Data preprocessing: Our initial dataset had its features encoded, so we run a simple script to rename them, as before, but keep the numerical codes intact.  We make a minor change to label missing values in the icd9 column to code 100, which is simply to keep them encoded.  We then split the dataset into training and testing sets, and normalize our target variable, which is payment. \n",
    "\n",
    "Model training: Train each model using the training set. For SGD Regression and SGD Classification, we will tune the learning rate and regularization parameters using grid search or random search methods. For Kernel approximation, we will choose an appropriate kernel function and tune the necessary parameters.\n",
    "\n",
    "Cross-validation: To ensure the robustness of our models and avoid overfitting, we will perform k-fold cross-validation during the training process. This involves splitting the training data into k subsets and training the model k times, using a different subset as the validation set in each iteration.\n",
    "\n",
    "Evaluation metrics: For SGD Regression, we use Mean Squared Error (MSE) or R-squared. For SGD Classification and Kernel approximation, we use accuracy, precision, recall, or F1-score.\n",
    "\n",
    "Model selection: Compare the performance of the models based on the chosen evaluation metrics and select the model(s) that perform best on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0933a8ae",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd60ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.stats import uniform\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02651dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path of the directory containing the script file\n",
    "script_dir = os.path.abspath(os.getcwd())\n",
    "\n",
    "# Run clean_data.py in the same directory\n",
    "os.system(f\"python {os.path.join(script_dir, 'encode_data.py')}\")\n",
    "\n",
    "# Load the encoded data\n",
    "data_filepath = os.path.join(script_dir, 'data_encoded.csv')\n",
    "pr_data = pd.read_csv(data_filepath)\n",
    "\n",
    "# Mark categorical variables\n",
    "categorical_columns = ['gender', 'age', 'base_drg', 'icd9', 'length', 'quintile']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    pr_data[column] = pr_data[column].astype('category')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = pr_data[['gender','age','base_drg', 'icd9', 'length']]\n",
    "y = pr_data['payment']\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X, columns=categorical_columns[:4])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=13\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb0bfd",
   "metadata": {},
   "source": [
    "### SGD Regression\n",
    "We scale the payment variable and run SGDRegressor with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f700c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 18622879.26121427\n",
      "Root Mean Squared Error: 4315.423416214714\n",
      "Mean Absolute Error: 2811.848570067721\n",
      "R-squared: 0.6067524988143489\n"
     ]
    }
   ],
   "source": [
    "# Scale the target variable using standard scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y_train_scaled = scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_train_scaled = y_train_scaled.ravel()\n",
    "\n",
    "y_test_scaled = scaler.transform(y_test.values.reshape(-1, 1))\n",
    "y_test_scaled = y_test_scaled.ravel()\n",
    "\n",
    "\n",
    " # Fit the SGDRegressor model on the training data and make predictions on the testing data\n",
    "sgd_reg = SGDRegressor(random_state=13)\n",
    "sgd_reg.fit(X_train, y_train_scaled)\n",
    "y_pred_scaled = sgd_reg.predict(X_test)\n",
    "\n",
    "\n",
    "# Inverse transform the scaled predictions to the original scale\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "y_pred = y_pred.ravel()\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906b100",
   "metadata": {},
   "source": [
    "#### SGD regression results\n",
    "  The model seems to have a fair performance, given that it explains about 61.27% of the variability in the data. However, the RMSE and MAE values indicate that there might be a significant amount of error in the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fde06",
   "metadata": {},
   "source": [
    "#### Hypertuning\n",
    "A model can sometimes be improved through hyperparameter tuning.  One way to do this is through randomized parameter searching.  Randomized search operates by sampling a given number of candidates from a parameter space with a specified distribution. For each of these candidates, which is a specific combination of hyperparameters, it performs cross-validation and estimates the model's performance.  Once the best combination is found, it is evaluated on the test set of data.  This example uses 3 folds and 20 parameter vectors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44d8ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/kevin/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/kevin/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by random search: {'alpha': 0.005436205927199517, 'epsilon': 0.19084774223440917, 'eta0': 0.2855046715791315, 'learning_rate': 'adaptive', 'loss': 'squared_error', 'penalty': None} \n",
      "\n",
      "Mean Squared Error: 18813142.236082554\n",
      "Root Mean Squared Error: 4337.411928337284\n",
      "Mean Absolute Error: 2797.6748776887957\n",
      "R-squared: 0.6027348365406677\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter distribution\n",
    "param_dist = {\n",
    "    'alpha': uniform(0.0001, 0.01),\n",
    "    'epsilon': uniform(0.1, 1),\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'eta0': uniform(0.01, 1),\n",
    "}\n",
    "\n",
    "# Initiate the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    SGDRegressor(random_state=13),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # number of parameter settings that are sampled\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    random_state=13,\n",
    "    n_jobs=-1,  # use all processors\n",
    ")\n",
    "\n",
    "# Fit it to the data\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters found by random search:', random_search.best_params_, '\\n')\n",
    "\n",
    "# Evaluate the model with the best found parameters on the testing data\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_scaled = best_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predictions to the original scale\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "y_pred = y_pred.ravel()\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eda7f2",
   "metadata": {},
   "source": [
    "#### Hypertuning Results\n",
    "Comparing these two results, we can see that the hyperparameter tuning using RandomSearchCV did not significantly improve the model's performance. In fact, the performance got slightly worse in terms of Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared, while only the Mean Absolute Error (MAE) decreased slightly.\n",
    "\n",
    "It's important to remember that this is a simplified scenario. A more comprehensive strategy would involve raising the count of parameter vectors and the cross-validation folds. However, this comes with its own set of challenges. The expansion of folds or parameter samples necessitates an equivalent increase in computational time. Given the circumstances, this might not always be a feasible or worthwhile trade-off. As it stands, with an R-squared value of .60, the model's performance is acceptable for a variety of applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e66ce4",
   "metadata": {},
   "source": [
    "### SGD Classifier\n",
    "This is similar, but will target payment quintiles, rather than payment amounts.  This code includes a random search hyperparameter tuning element as well.  Since this is a classification problem, our error measurements will be slightly different.  Our model will be scored on precision, accuracy, f1-score, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8fb8445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "Best parameters found by random search: {'alpha': 0.00768584003548691, 'epsilon': 0.7764953624318406, 'eta0': 0.61126991076597, 'learning_rate': 'invscaling', 'loss': 'modified_huber', 'penalty': 'l2'} \n",
      "\n",
      "Accuracy: 27.38%\n",
      "Precision: 55.83%\n",
      "Recall: 27.38%\n",
      "F1 Score: 18.73%\n",
      "[CV] END alpha=0.00768584003548691, epsilon=0.7764953624318406, eta0=0.61126991076597, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time= 2.2min\n",
      "[CV] END alpha=0.00768584003548691, epsilon=0.7764953624318406, eta0=0.61126991076597, learning_rate=invscaling, loss=modified_huber, penalty=l2; total time= 2.2min\n",
      "[CV] END alpha=0.007877024105738201, epsilon=0.3137870980314211, eta0=0.8260357473347548, learning_rate=constant, loss=log_loss, penalty=None; total time= 2.7min\n",
      "[CV] END alpha=0.007877024105738201, epsilon=0.3137870980314211, eta0=0.8260357473347548, learning_rate=constant, loss=log_loss, penalty=None; total time= 2.7min\n"
     ]
    }
   ],
   "source": [
    "# Combine 'base_drg' and 'quintile' into a single target variable\n",
    "pr_data['drg_quintile'] = pr_data['base_drg'].astype(str) + \"_\" + pr_data['quintile'].astype(str)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = pr_data[['base_drg', 'gender', 'age', 'icd9', 'length']]\n",
    "y = pr_data['drg_quintile']\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X, columns=['base_drg', 'icd9'])\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "# Specify the hyperparameter distribution\n",
    "param_dist = {\n",
    "    'alpha': uniform(loc=0.0001, scale=0.01),\n",
    "    'epsilon': uniform(loc=0.1, scale=0.9),\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'loss': ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'eta0': uniform(loc=0.01, scale=0.99),\n",
    "}\n",
    "\n",
    "# Initiate the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    SGDClassifier(random_state=13),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=2,\n",
    "    cv=2,\n",
    "    random_state=13,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit it to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters found by random search:', random_search.best_params_, '\\n')\n",
    "\n",
    "# Evaluate the model with the best found parameters on the testing data\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1 Score: {:.2f}%\".format(f1 * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cfd1df",
   "metadata": {},
   "source": [
    "#### Results  \n",
    "An accuracy rating of 27% means it is almost three times as likely to be wrong instead of right.  A precision score of 55% means that a positive guess has a 45% chance of being a false positive.  A recall of 27% means that it misses a lot of positive predictions, it has a lot of false negative results.  Even with a couple of different parameter sets, this performs poorly.  Increasing the parameter search may yield better results, but will add time.  As printed above, the random search added 10 minutes.  For our purporses, it may be worth investigating other options instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb306a1",
   "metadata": {},
   "source": [
    "### Random Forest Regression\n",
    "We return to predicting a quantity instead of a category.  Random forest approaches the problem differently than the standard sgd model, which is linear.  Random forest uses decision trees, which are nonlinear, and may better fit our dataset, since there is no obviously linear relationship between claim payments and any of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbbc597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 17174351.4990057\n",
      "Root Mean Squared Error: 4144.194915662836\n",
      "Mean Absolute Error: 2671.2313537808127\n",
      "R-squared: 0.6373401386146524\n"
     ]
    }
   ],
   "source": [
    "# Load the encoded data\n",
    "pr_data = pd.read_csv('/home/kevin/portfolio.git/data_encoded.csv')\n",
    "\n",
    "# Mark categorical variables\n",
    "categorical_columns = ['gender', 'age',\n",
    "                       'base_drg', 'icd9', 'length']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    pr_data[column] = pr_data[column].astype('category')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = pr_data[['gender', 'age', 'base_drg', 'icd9', 'length']]\n",
    "y = pr_data['payment']\n",
    "\n",
    "X = pr_data[categorical_columns]\n",
    "y = pr_data['payment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=13\n",
    ")\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbe311",
   "metadata": {},
   "source": [
    "#### Results\n",
    "The random forest regression performs better than the sgd regression, with an r-squared of .63 instead of 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee6c0ac",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373aeb17",
   "metadata": {},
   "source": [
    "## Performance Recap\n",
    "We used three distinct models to predict healthcare costs.  Stochastic Gradient Descent (SGD) Regression, SGD Classification, and Random Forest Regression.  SGD and Random forest regressions predicted payment values.  SGD Classification predicted quintile bins.  We trained and evaluated the models across several performance metrics. Results indicated varying degrees of success.   The SGD Regression model, for instance, explained about 61.27% of the variability in the data, suggesting room for improvement, while the Random Forest Regression model performed slightly better with an R-squared of .63. Hyperparameter tuning, did not significantly improve performance.  The SGD Classifier's performance was subpar, with an accuracy rating of 27%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f026b74",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "Our dataset presents several limitations that render it a less than ideal candidate for advanced prediction models. First, in order to maintain the confidentiality and de-identification of medical claims information, all our features have been converted into categorical variables. Age, length of stay, and other variables have been categorized instead of being left as continuous quantities. Even our other categorical variables have been aggregated or grouped, causing significant information loss. For example, our base DRG variable is a composite of up to three regular DRG codes. Additionally, our payment information has been grouped and averaged, leading to quintile bin averages. This results in a lack of granularity that presents challenges for accurate prediction.\n",
    "\n",
    "Secondly, our approach has been constrained due to the limited number of iterations in hyperparameter tuning, and we have only examined a couple of regression models. This trade-off inherently prioritizes time efficiency over accuracy, as further improvements via a more detailed grid search or exploration of other models might have yielded additional insights. However, despite these limitations, achieving an R-squared of .63 represents a moderate success for this demonstration of technique, considering the dataset's constraints."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
